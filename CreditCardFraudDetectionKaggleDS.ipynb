{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CreditCardFraudDetectionKaggleDS.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/MarcinWylot/CreditCardFraudDetectionKaggleDS/blob/master/CreditCardFraudDetectionKaggleDS.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "p7ORVdyQluC9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "skq9kg0-SKQB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f34b3df7-c5f8-4ada-a87c-f00a0f3faec1"
      },
      "cell_type": "code",
      "source": [
        "#from google.colab import files\n",
        "#uploaded = files.upload()\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# PyDrive reference:\n",
        "# https://googledrive.github.io/PyDrive/docs/build/html/index.html\n",
        "\n",
        "# 2. Create & upload a file text file.\n",
        "#uploaded = drive.CreateFile({'title': 'Sample upload.txt'})\n",
        "#uploaded.SetContentString('Sample upload file content')\n",
        "#uploaded.Upload()\n",
        "#print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
        "\n",
        "# 3. Load a file by ID and print its contents.\n",
        "downloaded = drive.CreateFile({'id': '1QQara53mzPKgRO4poTIWtQ2Ijm3GcqkV'})\n",
        "#print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))\n",
        "downloaded.GetContentFile('./creditcard.csv')\n",
        "!ls\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pc4ClwU49BKg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f60f97d0-5c59-49b0-f036-8e18366b64fa"
      },
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('./creditcard.csv')\n",
        "data = data.drop(['Time'], axis=1)\n",
        "data['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
        "#data.describe()\n",
        "X_train_full, X_test = train_test_split(data, test_size=0.2, random_state=0)\n",
        "\n",
        "#X_train = data[data.Class == 0]\n",
        "X_train = X_train_full\n",
        "y_train = X_train['Class']\n",
        "X_train = X_train.drop(['Class'], axis=1)\n",
        "#X_train = X_train.values\n",
        "\n",
        "y_test = X_test['Class']\n",
        "X_test = X_test.drop(['Class'], axis=1)\n",
        "#X_test = X_test.values\n",
        "\n",
        "\n",
        "fraud = X_train_full[X_train_full['Class'] == 1]\n",
        "valid = X_train_full[X_train_full['Class'] == 0]\n",
        "\n",
        "fraud_fraction = len(fraud) / float(len(valid))\n",
        "print(fraud_fraction)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0017190289025473282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TheFqdB3g5I_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "caace72c-999b-4909-d498-9f7ed94c24e2"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "clf_IsolationForest = IsolationForest(max_samples = len(X_test), contamination = fraud_fraction, random_state=1)\n",
        "\n",
        "clf_IsolationForest.fit(X_train)\n",
        "y_IsolationForest = clf_IsolationForest.predict(X_test)\n",
        "\n",
        "y_IsolationForest[y_IsolationForest == 1] = 0\n",
        "y_IsolationForest[y_IsolationForest == -1] = 1\n",
        "\n",
        "print(accuracy_score(y_test,y_IsolationForest))\n",
        "print(classification_report(y_test,y_IsolationForest))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9976475545100242\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       1.00      1.00      1.00     56861\n",
            "          1       0.33      0.33      0.33       101\n",
            "\n",
            "avg / total       1.00      1.00      1.00     56962\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YnH8VSrCg5WW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "004b5401-ff22-48cc-8253-002a5bf81a8f"
      },
      "cell_type": "code",
      "source": [
        "#it's not the best method to test unseen data \n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "clf_LocalOutlierFactor = LocalOutlierFactor(n_neighbors=20, contamination = fraud_fraction)\n",
        "\n",
        "clf_LocalOutlierFactor.fit(X_train)\n",
        "y_LocalOutlierFactor = clf_LocalOutlierFactor._decision_function(X_test)\n",
        "\n",
        "threshold = np.histogram(y_LocalOutlierFactor,bins=2)[1][1]\n",
        "\n",
        "y_pred = np.zeros(X_test.shape[0], dtype=int)\n",
        "y_pred[y_LocalOutlierFactor < threshold] = 1\n",
        "\n",
        "      \n",
        "print(accuracy_score(y_test,y_pred)) \n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9981039991573329\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       1.00      1.00      1.00     56861\n",
            "          1       0.00      0.00      0.00       101\n",
            "\n",
            "avg / total       1.00      1.00      1.00     56962\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B8PsT4htilFX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "bb864caa-80cf-49c9-c174-374016484aaf"
      },
      "cell_type": "code",
      "source": [
        "#https://medium.com/@curiousily/credit-card-fraud-detection-using-autoencoders-in-keras-tensorflow-for-hackers-part-vii-20e0c85301bd\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from keras import regularizers\n",
        "\n",
        "X_train = X_train_full[X_train_full.Class == 0] #we tain the model on normal transaction only \n",
        "y_train = X_train['Class']\n",
        "X_train = X_train.drop(['Class'], axis=1)\n",
        "X_train = X_train.values\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "encoding_dim = 14\n",
        "\n",
        "input_layer = Input(shape=(input_dim, ))\n",
        "encoder = Dense(encoding_dim, activation=\"tanh\", \n",
        "                activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
        "encoder = Dense(int(encoding_dim / 2), activation=\"relu\")(encoder)\n",
        "decoder = Dense(int(encoding_dim / 2), activation='tanh')(encoder)\n",
        "decoder = Dense(input_dim, activation='relu')(decoder)\n",
        "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
        "\n",
        "\n",
        "nb_epoch = 20\n",
        "batch_size = 32\n",
        "autoencoder.compile(optimizer='adam', \n",
        "                    loss='mean_squared_error', \n",
        "                    metrics=['accuracy'])\n",
        "checkpointer = ModelCheckpoint(filepath=\"model.h5\",\n",
        "                               verbose=0,\n",
        "                               save_best_only=True)\n",
        "tensorboard = TensorBoard(log_dir='./logs',\n",
        "                          histogram_freq=0,\n",
        "                          write_graph=True,\n",
        "                          write_images=True)\n",
        "history = autoencoder.fit(X_train, X_train,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    shuffle=True,\n",
        "                    validation_data=(X_test, X_test),\n",
        "                    verbose=0,\n",
        "                    callbacks=[checkpointer, tensorboard]).history\n",
        "\n",
        "\n",
        "predictions = autoencoder.predict(X_test)\n",
        "\n",
        "mse = np.mean(np.power(X_test - predictions, 2), axis=1)\n",
        "error_df = pd.DataFrame({'reconstruction_error': mse,\n",
        "                        'true_class': y_test})\n",
        "\n",
        "print(np.histogram(error_df.reconstruction_error.values,bins=4))\n",
        "#threshold = np.histogram(y_LocalOutlierFactor,bins=2)[1][1]\n",
        "threshold = 3\n",
        "y_pred = np.zeros(X_test.shape[0], dtype=int)\n",
        "y_pred[y_LocalOutlierFactor > threshold] = 1\n",
        "\n",
        "print(accuracy_score(y_test,y_pred)) \n",
        "print(classification_report(error_df.true_class,y_test))"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(array([56961,     1]), array([8.06259820e-02, 8.12961644e+02, 1.62584266e+03]))\n",
            "0.9783188792528352\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       1.00      1.00      1.00     56861\n",
            "          1       1.00      1.00      1.00       101\n",
            "\n",
            "avg / total       1.00      1.00      1.00     56962\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mVhL5tbYyyCz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "be10b732-3935-4f62-ed62-621eb223c565"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       1.00      0.98      0.99    284315\n",
            "          1       0.06      0.82      0.12       492\n",
            "\n",
            "avg / total       1.00      0.98      0.99    284807\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}